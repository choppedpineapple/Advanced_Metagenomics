## scFv Reconstruction Pipeline

This repository contains a reproducible workflow for reconstructing single-chain variable fragment (scFv) sequences from fragmented, merged Illumina reads. The pipeline was developed and validated on a mock dataset but is designed to scale to large libraries (~5 GB) with substantial coverage.

### Quick Start

```bash
# First make the runner executable (only needed once)
chmod +x run_scfv_pipeline.sh

# Optional: copy the bundled mock dataset into place
cp mock_data/merged.fastq /desired/location/

# Run the pipeline (prompts for the input FASTQ if omitted)
bash run_scfv_pipeline.sh /path/to/merged.fastq /path/to/output_dir
```

The script writes all intermediate files and final artefacts into `/path/to/output_dir`. The most relevant deliverables are collected under `final_results/` (trimmed consensus FASTA, QC tables, coverage stats, known scFv reference sequences, and per-clone assigned read sets).

### Requirements

| Component                 | Notes                                                                                           |
|--------------------------|-------------------------------------------------------------------------------------------------|
| Python 3.11+             | Used for orchestration scripts (no external Python packages required).                          |
| Conda environment `scfv` | Must contain `seqkit`, `bbmap`, `vsearch`, `spades`, `spoa`, and `bowtie2` (see below).          |
| POSIX shell utilities    | Standard `bash`, `coreutils` commands.                                                          |

Create the conda environment if it does not already exist:

```bash
conda create -y -n scfv -c conda-forge -c bioconda \
  seqkit bbmap vsearch spades bowtie2 spoa
```

Ensure the `conda` base executables are on your `PATH` so that `conda run` is available.

### Repository Layout

```
run_scfv_pipeline.sh                     # Bash entrypoint
scripts/
  extract_linker_regions.py              # Detect linker hits and orient reads
  partition_by_cluster.py                # Group reads by CDR3 consensus
  seed_extend.py                         # Orientation-aware read extension helper
  run_scfv_pipeline.py                   # Python orchestrator invoked by the bash wrapper
reference/
  mock_truth_scfv.fa                     # Known scFv sequences for validation
mock_data/
  merged.fastq                          # Example dataset (synthetic)
```

All intermediate and final outputs are created inside the user-specified analysis directory (default: `analysis_runs/run_<timestamp>`).

### Pipeline Overview

1. **Linker detection & orientation**  
   `scripts/extract_linker_regions.py` scans the merged FASTQ, re-orienting reads so the 41 bp linker (`GGTGCT…`) is forward. Upstream (VH) and downstream (VL) fragments, as well as 60 bp CDR3 windows, are exported for clustering.

2. **CDR3 clustering**  
   High-quality CDR3 windows (≤2 ambiguous bases) are clustered at 99 % identity via `vsearch`. This approximates the distinct VH repertoires in the library.

3. **Read partitioning**  
   `scripts/partition_by_cluster.py` assigns every linker-positive read to the nearest CDR3 centroid, writing per-cluster FASTQs plus a manifest table.

4. **Initial consensus generation**  
   Each cluster FASTQ is collapsed with `spoa` to form a seed consensus.

5. **Iterative recruitment & extension**  
   For each cluster, `scripts/run_scfv_pipeline.py` orchestrates several rounds of:
   - seed extension (`seed_extend.py`) using cluster reads,
   - global read recruitment with `bbmap.sh` at progressively relaxed identity thresholds (95 %, 90 %, 85 %, 80 %),
   - consensus regeneration with `spoa`.
   Iterations stop once the consensus stops growing or reaches ~700 bp.

6. **Assembly cross-check (SPAdes)**  
   The final read set per cluster is assembled with `spades.py` (isolate mode) to confirm contig structure.

7. **Orientation, trimming & QC**  
   The final consensus is oriented so that the linker is forward, and a VH+linker+VL window (≈360 bp either side) is trimmed. Coverage statistics (`bbmap.sh covstats`) and best-match comparisons to known scFv sequences are reported in `final_results/qc_summary.tsv`.

8. **Deliverables**  
   - `final_results/scfv_consensus_trimmed.fa`: Forward-oriented VH-linker-VL sequences (complete or partial).  
   - `final_results/scfv_consensus_raw.fa`: Full consensus before trimming.  
   - `final_results/qc_summary.tsv`: Cluster-level metadata (lengths, coverage, best known match, status).  
   - `final_results/assigned_reads/`: FASTQs of reads assigned to each cluster.  
   - `final_results/coverage/`: Coverage tables generated by BBMap.  
   - `final_results/known_scfv.fa`: Reference sequences to enable downstream comparisons.

### Customisation

Important command-line options (see `python scripts/run_scfv_pipeline.py --help` for the complete list):

| Option                | Description                                              | Default |
|-----------------------|----------------------------------------------------------|---------|
| `--linker`            | Linker sequence (forward orientation).                   | 41 bp VH-linker-VL |
| `--min-cluster-size`  | Minimum reads per cluster before extension.              | 30      |
| `--conda-env`         | Conda environment name used for external binaries.       | scfv    |
| `--known-scfv`        | FASTA of expected/known scFv sequences.                  | `reference/mock_truth_scfv.fa` |

### Outputs for the Mock Dataset

Running `bash run_scfv_pipeline.sh mock_data/merged.fastq analysis_runs/mock_test` produces, in `analysis_runs/mock_test/final_results/`:

| File                                   | Description                                                         |
|----------------------------------------|---------------------------------------------------------------------|
| `scfv_consensus_trimmed.fa`            | Trimmed consensus sequences (forward orientation).                  |
| `scfv_consensus_raw.fa`                | Raw consensus sequences prior to trimming.                          |
| `qc_summary.tsv`                       | Tab-delimited QC metrics per cluster (lengths, coverage proxy, etc).|
| `assigned_reads/cluster_X.fastq`       | Reads recruited into each reconstructed scFv.                       |
| `coverage/cluster_X_covstats.txt`      | BBMap coverage statistics for each consensus.                       |
| `known_scfv.fa`                        | Reference scFv sequences used for comparison.                       |

Clusters in the synthetic dataset demonstrate the pipeline’s ability to:

- Reconstruct full-length VH-linker-VL sequences (clusters 1 & 3 – status `complete`).  
- Flag incomplete reconstructions where coverage is insufficient (cluster 2 – status `partial`).

### Troubleshooting

| Issue                                        | Suggested Resolution                                                                                 |
|----------------------------------------------|-------------------------------------------------------------------------------------------------------|
| `Command failed …` in `pipeline.log`         | Inspect the logged command and rerun manually to diagnose (missing tool, wrong conda env, permissions). |
| No clusters detected (`cluster_manifest.tsv` empty) | Reduce `--min-cluster-size` or verify the linker sequence matches your dataset.                        |
| Memory issues during FASTQ merging           | Increase system RAM or run on a machine with more memory; the merging step stores read IDs in memory. |
| Coverage flagged as `partial` despite high depth | Check for linker sequence variants; consider relaxing seed lengths or adding alternative linker motifs. |

### Extending to Real Datasets

- Ensure R1/R2 reads are merged (or adjust the workflow to operate on paired-end datasets).  
- High coverage (>100×) is recommended to enable the extension logic to recover full-length VH/VL regions.  
- Update `reference/` with the set of scFv sequences you expect to recover for downstream validation.  
- Review `ITERATION_CONFIG` inside `scripts/run_scfv_pipeline.py` to tailor the recruitment thresholds for your library.

### Support

The log file (`pipeline.log` inside each analysis directory) captures every command executed, making it straightforward to audit or rerun individual steps manually. For further customisation, adapt the helper scripts in `scripts/`—they are self-contained and rely only on the tools listed in the requirements.
